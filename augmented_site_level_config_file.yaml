spark-hadoop-master-expected-from-site-level-config:
  spark_hadoop_master_default_var_spark_event_log_enabled: true
  spark_hadoop_master_default_var_spark_event_log_dir: spark-logs
  spark_hadoop_master_default_var_hdfs_dfs_replication: 1
  spark_hadoop_master_default_var_yarn_app_mapreduce_am_resource_mb: 512
  spark_hadoop_master_default_var_mapreduce_map_memory_mb: 256
  spark_hadoop_master_default_var_mapreduce_reduce_memory_mb: 256
  spark_hadoop_master_default_var_yarn_nodemanager_resource_memory_mb: 1536
  spark_hadoop_master_default_var_yarn_scheduler_maximum_allocation_mb: 1536
  spark_hadoop_master_default_var_yarn_scheduler_minimum_allocation_mb: 128
spark_hadoop_worker_runtime_variables:
- spark-hadoop-master.cern.ch
default_group_opssgm:
  gid: 46001
  name: opssgm
default_pool_accounts_alicesgm:
  base_name: sgmali
  initial_uid: 60101
  users_num: 10
  primary_group:
    gid: 1397
    name: alicesgm
  secondary_groups:
  - gid: 1395
    name: alice
default_group_ops_name: ops
default_pool_accounts_alice:
  base_name: alice
  initial_uid: 10417
  users_num: 5
  primary_group:
    gid: 1395
    name: alice
  secondary_groups: []
default_group_dteamsgm:
  gid: 2680
  name: dteamsgm
preferred_tech_stack:
  level_1_configuration: puppet
  level_2_configuration: sh
  container_orchestration: docker-swarm
  container: docker
default_pool_accounts_dteam:
  base_name: dteam
  initial_uid: 18118
  users_num: 10
  primary_group:
    gid: 2688
    name: dteam
  secondary_groups: []
default_vo_dteam:
  name: dteam
  servers:
  - server: voms2.cern.ch
    port: '15001'
    dn: /DC=ch/DC=cern/OU=computers/CN=voms2.cern.ch
    ca_dn: /DC=ch/DC=cern/CN=CERN Grid Certification Authority
  - server: lcg-voms2.cern.ch
    port: '15001'
    dn: /DC=ch/DC=cern/OU=computers/CN=lcg-voms2.cern.ch
    ca_dn: /DC=ch/DC=cern/CN=CERN Grid Certification Authority
  default_se: not_used.some-domain
  sw_dir: .
  storage_dir: /storage/dteam
default_group_ops:
  gid: 45000
  name: ops
default_group_alicesgm_name: alicesgm
spark-hadoop-worker-expected-from-site-level-config:
  spark_hadoop_worker_default_var_fs_default_name: spark-hadoop-master.cern.ch
  spark_hadoop_worker_default_var_yarn_resource_manager_hostname: spark-hadoop-master.cern.ch
  spark_hadoop_worker_default_var_hdfs_dfs_replication: 1
  spark_hadoop_worker_default_var_yarn_app_mapreduce_am_resource_mb: 512
  spark_hadoop_worker_default_var_mapreduce_map_memory_mb: 256
  spark_hadoop_worker_default_var_mapreduce_reduce_memory_mb: 256
  spark_hadoop_worker_default_var_yarn_nodemanager_resource_memory_mb: 1536
  spark_hadoop_worker_default_var_yarn_scheduler_maximum_allocation_mb: 1536
  spark_hadoop_worker_default_var_yarn_scheduler_minimum_allocation_mb: 128
  spark_hadoop_worker_default_var_spark_event_log_enabled: true
  spark_hadoop_worker_default_var_spark_event_log_dir: spark-logs
  spark_hadoop_worker_default_var_spark_driver_memory: 512m
  spark_hadoop_worker_default_var_spark_executor_memory: 512m
  spark_hadoop_worker_default_var_spark_yarn_am_memory: 512m
  spark_hadoop_worker_default_var_spark_history_fs_log_directory: spark-logs
  spark_hadoop_worker_default_var_spark_history_fs_update_interval: 30s
site_infrastructure:
- fqdn: spark-hadoop-master.cern.ch
  ip_address: 188.185.104.49
- fqdn: spark-hadoop-worker.cern.ch
  ip_address: 188.184.85.219
default_pool_accounts_dteamsgm:
  base_name: sgmdtm
  initial_uid: 60501
  users_num: 5
  primary_group:
    gid: 2680
    name: dteamsgm
  secondary_groups:
  - gid: 2688
    name: dteam
default_group_alice_name: alice
default_vo_generic_dn_ca_cern: /DC=ch/DC=cern/CN=CERN Grid Certification Authority
default_group_alicesgm:
  gid: 1397
  name: alicesgm
default_vo_alice:
  name: alice
  servers:
  - server: voms2.cern.ch
    port: '15000'
    dn: /DC=ch/DC=cern/OU=computers/CN=voms2.cern.ch
    ca_dn: /DC=ch/DC=cern/CN=CERN Grid Certification Authority
  - server: lcg-voms2.cern.ch
    port: '15000'
    dn: /DC=ch/DC=cern/OU=computers/CN=lcg-voms2.cern.ch
    ca_dn: /DC=ch/DC=cern/CN=CERN Grid Certification Authority
  default_se: not_used.some-domain
  sw_dir: .
  storage_dir: /not/used
default_vo_generic_server_primary: voms2.cern.ch
default_vo_ops:
  name: ops
  servers:
  - server: voms2.cern.ch
    port: '15009'
    dn: /DC=ch/DC=cern/OU=computers/CN=voms2.cern.ch
    ca_dn: /DC=ch/DC=cern/CN=CERN Grid Certification Authority
  - server: lcg-voms2.cern.ch
    port: '15009'
    dn: /DC=ch/DC=cern/OU=computers/CN=lcg-voms2.cern.ch
    ca_dn: /DC=ch/DC=cern/CN=CERN Grid Certification Authority
  default_se: not_used.some-domain
  sw_dir: .
  storage_dir: /storage/ops
default_group_dteam:
  gid: 2688
  name: dteam
default_vo_generic_dn_server_secondary: /DC=ch/DC=cern/OU=computers/CN=lcg-voms2.cern.ch
meta_info_spark-hadoop-worker:
  component: spark-hadoop-worker
  type: spark_hadoop_worker
  version: 1.0.0
  docker_hub_tag: ''
  site_level_config_version: 1.0
  default_var_prefix: spark_hadoop_worker_default_var
  runtime_vars:
  - spark_hadoop_worker_runtime_var_spark_hadoop_master_fqdn
  docker_run_parameters:
    hostname: container_fqdn
    privileged: true
    detached: true
    tty: true
    ssh_client: true
default_pool_account_ops:
  base_name: ops
  initial_uid: 45001
  users_num: 10
  primary_group:
    gid: 45000
    name: ops
  secondary_groups: []
default_pool_account_opssgm:
  base_name: sgmops
  initial_uid: 60701
  users_num: 10
  primary_group:
    gid: 45000
    name: ops
  secondary_groups:
  - gid: 46001
    name: opssgm
default_group_alice:
  gid: 1395
  name: alice
default_group_dteamsgm_name: dteamsgm
default_group_opssgm_name: opssgm
default_vo_generic_dn_server_primary: /DC=ch/DC=cern/OU=computers/CN=voms2.cern.ch
default_vo_generic_server_secondary: lcg-voms2.cern.ch
lightweight_components:
- name: spark-hadoop-master
  deploy:
    node: spark-hadoop-master.cern.ch
    container_count: 1
  config:
    spark_history_fs_log_directory: hdfs://spark-hadoop-master.cern.ch:9000/spark-logs
    spark_executor_memory: 1g
    yarn_scheduler_maximum_allocation_mb: 1536
    spark_event_log_dir: spark-logs
    spark_driver_memory: 1g
    yarn_app_mapreduce_am_resource_mb: 512
    yarn_nodemanager_resource_memory_mb: 1536
    spark_history_fs_update_interval: 30s
    yarn_scheduler_minimum_allocation_mb: 128
    hdfs_dfs_replication: 1
    mapreduce_map_memory_mb: 256
    spark_event_log_enabled: true
    spark_yarn_am_memory: 512m
    mapreduce_reduce_memory_mb: 256
  repository_revision: master
  supplemental_config:
    spark-defaults.conf:
    - spark.driver.cores 1
  repository_url: https://github.com/maany/simple_spark_cluster_master
  type: spark_hadoop_master
  container_count: 1
  id: 0
  execution_id: 0
- name: spark-hadoop-worker
  deploy:
    node: spark-hadoop-worker.cern.ch
    container_count: 1
  config:
    spark_history_fs_log_directory: spark-logs
    spark_event_log_enabled: true
    spark_event_log_dir: spark-logs
    yarn_scheduler_maximum_allocation_mb: 1536
    spark_driver_memory: 512m
    yarn_app_mapreduce_am_resource_mb: 512
    yarn_nodemanager_resource_memory_mb: 1536
    spark_yarn_am_memory: 512m
    spark_history_fs_update_interval: 30s
    yarn_scheduler_minimum_allocation_mb: 128
    hdfs_dfs_replication: 1
    mapreduce_map_memory_mb: 256
    spark_executor_memory: 512m
    fs_default_name: spark-hadoop-master.cern.ch
    yarn_resource_manager_hostname: spark-hadoop-master.cern.ch
    mapreduce_reduce_memory_mb: 256
  repository_revision: master
  supplemental_config:
    spark-defaults.conf:
    - spark.driver.cores 1
  repository_url: https://github.com/maany/simple_spark_cluster_worker
  type: spark_hadoop_worker
  container_count: 1
  id: 1
  execution_id: 1
global_variables:
- 188.185.104.49
- spark-hadoop-master.cern.ch
- 188.184.85.219
- spark-hadoop-worker.cern.ch
meta_info_spark-hadoop-master:
  component: spark-hadoop-master
  type: spark_hadoop_master
  version: 1.0.0
  docker_hub_tag: ''
  site_level_config_version: 1.0
  default_var_prefix: spark_hadoop_master_default_var
  host_requirements:
    firewall:
    - ports: 8080
      protocol: tcp
      action: accept
      ipv6: true
    - ports: 7077
      protocol: tcp
      action: accept
      ipv6: true
    - ports: 6066
      protocol: tcp
      action: accept
      ipv6: true
    - ports: 50070
      protocol: tcp
      action: accept
      ipv6: true
    - ports: 8088
      protocol: tcp
      action: accept
      ipv6: true
    - ports: 18080
      protocol: tcp
      action: accept
      ipv6: true
    - ports: 9000
      protocol: tcp
      action: accept
      ipv6: true
  docker_run_parameters:
    hostname: host_fqdn
    privileged: true
    detached: true
    tty: true
    ports:
    - 8080:8080
    - 7077:7077
    - 6066:6066
    - 50070:50070
    - 8088:8088
    - 18080:18080
    - 9000:9000
    ssh_server: true
    ssh_client: true
default_group_dteam_name: dteam

dns:
- container_fqdn: spark-hadoop-master.cern.ch
  host_fqdn: spark-hadoop-master.cern.ch
  host_ip: 188.185.104.49
  container_ip: 10.0.0.10
  type: spark_hadoop_master
  execution_id: 0
- container_fqdn: spark_hadoop_worker_localhost01_1.cern.ch
  host_fqdn: spark_hadoop_worker.cern.ch
  host_ip: 188.184.85.219
  container_ip: 10.0.0.11
  type: spark_hadoop_worker
  execution_id: 1